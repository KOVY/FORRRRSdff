### **Pokroƒçil√Ω startup script s kompletn√≠m workflow**
```bash
# Vytvo≈ô pokroƒçil√Ω startup script
cat > ~/ai-workspace/start-complete-workflow.sh << 'EOF'
#!/bin/bash

echo "üöÄ Starting Complete AI Workflow with Memory & RAG..."

# Aktivuj Python environment
cd ~/ai-workspace
source ai-env/bin/activate

# Start Ollama service
echo "üîÑ Starting Ollama..."
sudo systemctl start ollama
sleep 3

# Check if models are available
echo "üìã Checking AI models..."
ollama list

# Start ChromaDB (if needed)
echo "üîß Initializing RAG database..."
python -c "
import asyncio
from rag.rag_manager import rag_manager
asyncio.run(rag_manager.initialize_collections())
print('‚úÖ RAG database ready')
"

# Auto-index existing projects
echo "üß† Auto-indexing workspace projects..."
python -c "
import asyncio
from knowledge.indexer import indexer
asyncio.run(indexer.auto_index_workspace())
print('‚úÖ Projects indexed')
"

# Start MCP server with memory & RAG
echo "üåê Starting MCP server with Memory & RAG..."
nohup python mcp-server.py > mcp.log 2>&1 &
MCP_PID=$!

# Wait for MCP server to start
sleep 5

# Check if MCP server is running
if curl -s http://localhost:3001/health > /dev/null; then
    echo "‚úÖ MCP Server running on http://localhost:3001"
else
    echo "‚ö†Ô∏è MCP Server might not be ready yet"
fi

# Check GPU status
echo "üî• GPU Status:"
nvidia-smi --query-gpu=name,utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits

# Check memory and RAG status
echo "üß† Memory & RAG Status:"
echo "- ChromaDB collections: $(ls chroma_db/ 2>/dev/null | wc -l)"
echo "- Memory entries: Available"
echo "- RAG indices: Ready"

echo ""
echo "‚úÖ Complete AI Workflow ready!"
echo ""
echo "üí° Available capabilities:"
echo "  üéØ Context-aware code generation"
echo "  üß† Project memory (remembers patterns)"
echo "  üîç RAG code search (finds similar solutions)"  
echo "  üìö Learning from successful solutions"
echo "  üöÄ Smart project scaffolding"
echo "  üîß Memory-based optimization"
echo ""
echo "üéÆ VS Code Integration:"
echo "  ‚Ä¢ Open VS Code: code ."
echo "  ‚Ä¢ AI Chat: Ctrl+Shift+P ‚Üí 'Continue: Chat'"
echo "  ‚Ä¢ Smart Commands: Use custom commands in Continue.dev"
echo "  ‚Ä¢ Tasks: Ctrl+Shift+P ‚Üí 'Run Task'"
echo ""
echo "üìä Monitor with: Ctrl+Shift+P ‚Üí 'Run Task' ‚Üí 'AI Workflow Status'"
echo "üîç Search RAG: Ctrl+Shift+P ‚Üí 'Run Task' ‚Üí 'Search RAG Database'"
echo ""
EOF

chmod +x ~/ai-workspace/start-complete-workflow.sh
```

### **Vytvo≈ôen√≠ helper scriptu pro development**
```bash
# Vytvo≈ô development helper script
cat > ~/ai-workspace/ai-dev-helper.sh << 'EOF'
#!/bin/bash

# AI Development Helper Script
# Poskytuje rychl√© p≈ô√≠kazy pro AI workflow

case "$1" in
    "start")
        echo "üöÄ Starting AI Workflow..."
        ~/ai-workspace/start-complete-workflow.sh
        ;;
    "status")
        echo "üìä AI Workflow Status:"
        echo "=== Models ==="
        ollama list
        echo -e "\n=== GPU ==="
        nvidia-smi --query-gpu=name,utilization.gpu,memory.used --format=csv,noheader
        echo -e "\n=== MCP Server ==="
        curl -s http://localhost:3001/health | jq -r .message 2>/dev/null || echo "Offline"
        echo -e "\n=== RAG Database ==="
        echo "Collections: $(ls ~/ai-workspace/chroma_db/ 2>/dev/null | wc -l)"
        ;;
    "index")
        if [ -z "$2" ]; then
            echo "Usage: $0 index <project-path>"
            exit 1
        fi
        echo "üß† Indexing project: $2"
        cd ~/ai-workspace && source ai-env/bin/activate
        python -c "
import asyncio
from knowledge.indexer import indexer
asyncio.run(indexer._index_repository('$2'))
"
        ;;
    "search")
        if [ -z "$2" ]; then
            echo "Usage: $0 search <query>"
            exit 1
        fi
        echo "üîç Searching RAG for: $2"
        cd ~/ai-workspace && source ai-env/bin/activate
        python -c "
import asyncio
from rag.rag_manager import rag_manager
results = asyncio.run(rag_manager.search_similar_code('$2', limit=3))
print('RAG Search Results:')
for i, result in enumerate(results, 1):
    print(f'{i}. {result[\"metadata\"][\"file_path\"]}')
    print(f'   {result[\"content\"][:100]}...')
    print()
"
        ;;
    "memory")
        if [ -z "$2" ]; then
            PROJECT_PATH=$(pwd)
        else
            PROJECT_PATH="$2"
        fi
        echo "üíæ Project Memory for: $PROJECT_PATH"
        cd ~/ai-workspace && source ai-env/bin/activate
        python -c "
import asyncio
from memory.memory_manager import memory_manager
context = asyncio.run(memory_manager.get_project_context('$PROJECT_PATH'))
if context:
    print(f'Tech Stack: {context.get(\"tech_stack\", [])}')
    print(f'Architecture: {context.get(\"architecture\", \"N/A\")}')
    print(f'Last Updated: {context.get(\"last_updated\", \"N/A\")}')
    print(f'Patterns: {len(context.get(\"coding_patterns\", {}))} stored')
else:
    print('No memory found for this project')
"
        ;;
    "learn")
        if [ -z "$2" ] || [ -z "$3" ]; then
            echo "Usage: $0 learn <pattern-type> <description>"
            echo "Example: $0 learn 'react-component' 'Successful user card implementation'"
            exit 1
        fi
        echo "üìö Learning pattern: $2"
        cd ~/ai-workspace && source ai-env/bin/activate
        python -c "
import asyncio
from memory.memory_manager import memory_manager
pattern_data = {
    'description': '$3',
    'project_path': '$(pwd)',
    'success_score': 0.9,
    'reusable': True
}
asyncio.run(memory_manager.store_successful_pattern('$2', pattern_data))
print('‚úÖ Pattern learned and stored')
"
        ;;
    "reset")
        echo "üîÑ Resetting AI Workflow..."
        pkill -f "mcp-server.py"
        sudo systemctl restart ollama
        rm -rf ~/ai-workspace/chroma_db/*
        echo "‚úÖ Reset complete. Run '$0 start' to restart."
        ;;
    "backup")
        BACKUP_DIR="~/ai-backups/$(date +%Y%m%d_%H%M%S)"
        echo "üíæ Backing up AI data to $BACKUP_DIR"
        mkdir -p "$BACKUP_DIR"
        cp -r ~/ai-workspace/chroma_db "$BACKUP_DIR/"
        cp -r ~/ai-workspace/knowledge "$BACKUP_DIR/"
        echo "‚úÖ Backup completed"
        ;;
    "restore")
        if [ -z "$2" ]; then
            echo "Usage: $0 restore <backup-directory>"
            exit 1
        fi
        echo "üì• Restoring from $2"
        cp -r "$2/chroma_db" ~/ai-workspace/
        cp -r "$2/knowledge" ~/ai-workspace/
        echo "‚úÖ Restore completed"
        ;;
    *)
        echo "ü§ñ AI Development Helper"
        echo ""
        echo "Usage: $0 <command> [options]"
        echo ""
        echo "Commands:"
        echo "  start                    - Start complete AI workflow"
        echo "  status                   - Show AI workflow status"
        echo "  index <project-path>     - Index project into RAG database"
        echo "  search <query>           - Search RAG database"
        echo "  memory [project-path]    - Show project memory"
        echo "  learn <type> <desc>      - Store successful pattern"
        echo "  reset                    - Reset AI workflow"
        echo "  backup                   - Backup AI data"
        echo "  restore <backup-dir>     - Restore AI data"
        echo ""
        echo "Examples:"
        echo "  $0 start"
        echo "  $0 index /path/to/my-project"
        echo "  $0 search 'React hooks patterns'"
        echo "  $0 learn 'api-optimization' 'Fast PostgreSQL queries'"
        ;;
esac
EOF

chmod +x ~/ai-workspace/ai-dev-helper.sh

# Vytvo≈ô symlink pro glob√°ln√≠ p≈ô√≠stup
sudo ln -sf ~/ai-workspace/ai-dev-helper.sh /usr/local/bin/ai-dev
```

---

## üöÄ Krok 8: Test Complete AI Workflow

### **Kompletn√≠ test instalace s Memory & RAG**
```bash
# 1. Start complete AI workflow
~/ai-workspace/start-complete-workflow.sh

# 2. Test helper p≈ô√≠kazy
ai-dev status

# 3. Vytvo≈ô testovac√≠ projekt s AI
mkdir ~/test-smart-project
cd ~/test-smart-project

# 4. Inicializuj projekt p≈ôes AI
npx create-next-app@latest . --typescript --tailwind --eslint --app --yes

# 5. Index projekt do RAG
ai-dev index "$(pwd)"

# 6. Test VS Code s Continue.dev
code .
# Stiskni Ctrl+Shift+P ‚Üí "Continue: Chat"
# Zadej: "Pou≈æij project memory a RAG datab√°zi k vytvo≈ôen√≠ user dashboard komponenty"

# 7. Test RAG search
ai-dev search "React dashboard components"

# 8. Test project memory
ai-dev memory

# 9. Test learning
ai-dev learn "successful-setup" "Test project successfully created and indexed"
```

### **Pokroƒçil√© test prompts pro Continue.dev**
```bash
# Test v Continue.dev (Ctrl+Shift+P ‚Üí Continue: Chat):

# 1. Memory-aware prompt:
"Naƒçti kontext tohoto projektu z memory a vytvo≈ô user authentication syst√©m na z√°kladƒõ podobn√Ωch √∫spƒõ≈°n√Ωch implementac√≠ z RAG datab√°ze."

# 2. RAG search prompt:  
"Prohledej RAG datab√°zi pro najbol≈°√≠ React dashboard patterns a implementuj podobn√Ω dashboard s modern√≠mi features."

# 3. Learning prompt:
"Analyzuj tento k√≥d a ulo≈æ jako √∫spƒõ≈°n√Ω pattern pro budouc√≠ pou≈æit√≠: [vlo≈æ k√≥d]"

# 4. Context-aware optimization:
"Optimalizuj tento k√≥d na z√°kladƒõ √∫spƒõ≈°n√Ωch optimalizac√≠ z memory a similar patterns z RAG datab√°ze."

# 5. Smart architecture prompt:
"Navrhni architekturu pro e-commerce aplikaci s vyu≈æit√≠m v≈°ech dostupn√Ωch patterns z memory a RAG datab√°ze."
```

---

## üöÄ Krok 9: VS Code Workflow Integration

### **Vytvo≈ôen√≠ VS Code workspace s AI workflow**
```bash
# Vytvo≈ô AI-enhanced workspace
cat > ~/ai-workspace/ai-development.code-workspace << 'EOF'
{
  "folders": [
    {
      "name": "AI Workspace",
      "path": "."
    },
    {
      "name": "Projects",
      "path": "./projects"
    },
    {
      "name": "Templates",
      "path": "./templates"
    }
  ],
  "settings": {
    "aiWorkflow.enabled": true,
    "aiWorkflow.memoryPath": "./memory",
    "aiWorkflow.ragPath": "./chroma_db",
    "aiWorkflow.mcpServer": "http://localhost:3001",
    
    "continue.enableTabAutocomplete": true,
    "continue.telemetryEnabled": false,
    
    "python.defaultInterpreterPath": "./ai-env/bin/python",
    "python.terminal.activateEnvironment": true,
    
    "files.exclude": {
      "**/chroma_db": true,
      "**/ai-env": true,
      "**/__pycache__": true,
      "**/mcp.log": true
    },
    
    "search.exclude": {
      "**/chroma_db": true,
      "**/ai-env": true
    }
  },
  "tasks": {
    "version": "2.0.0",
    "tasks": [
      {
        "label": "üöÄ Start AI Workflow",
        "type": "shell",
        "command": "./start-complete-workflow.sh",
        "group": "build",
        "presentation": {
          "echo": true,
          "reveal": "always",
          "panel": "new"
        }
      },
      {
        "label": "üîç Quick RAG Search",
        "type": "shell",
        "command": "./ai-dev-helper.sh",
        "args": ["search", "${input:ragQuery}"],
        "group": "test"
      }
    ],
    "inputs": [
      {
        "id": "ragQuery",
        "description": "Co hled√°≈° v RAG datab√°zi?",
        "default": "React component patterns"
      }
    ]
  },
  "extensions": {
    "recommendations": [
      "continue.continue",
      "ms-python.python",
      "ms-vscode.vscode-typescript-next",
      "esbenp.prettier-vscode",
      "dbaeumer.vscode-eslint",
      "bradlc.vscode-tailwindcss",
      "ms-vscode.vscode-json"
    ]
  }
}
EOF

# Otev≈ôi AI workspace
code ~/ai-workspace/ai-development.code-workspace
```

### **Vytvo≈ôen√≠ project templates s AI**
```bash
# Vytvo≈ô templates s embedded AI workflow
mkdir -p ~/ai-workspace/templates

# React + AI template
cat > ~/ai-workspace/templates/create-ai-react-app.sh << 'EOF'
#!/bin/bash

PROJECT_NAME="$1"
if [ -z "$PROJECT_NAME" ]; then
    echo "Usage: $0 <project-name>"
    exit 1
fi

echo "üöÄ Creating AI-enhanced React project: $PROJECT_NAME"

# Vytvo≈ô projekt
npx create-next-app@latest "$PROJECT_NAME" --typescript --tailwind --eslint --app --yes
cd "$PROJECT_NAME"

# P≈ôidej AI development dependencies
npm install @prisma/client prisma
npm install --save-dev @types/node

# Inicializuj Prisma
npx prisma init

# Vytvo≈ô AI configuration
mkdir .ai
cat > .ai/project-config.json << 'JSON'
{
  "ai_enabled": true,
  "memory_tracking": true,
  "rag_indexing": true,
  "auto_optimization": true,
  "tech_stack": ["React", "Next.js", "TypeScript", "Tailwind CSS", "Prisma"],
  "patterns": {
    "component_style": "functional",
    "state_management": "hooks",
    "styling": "tailwind"
  }
}
JSON

# Index do RAG datab√°ze
ai-dev index "$(pwd)"

# Ulo≈æ do project memory
ai-dev learn "project-template" "AI-enhanced React project template created"

echo "‚úÖ AI-enhanced project $PROJECT_NAME created and indexed"
echo "üí° Open with: code $PROJECT_NAME"
echo "üéØ Use Continue.dev with context-aware prompts"
EOF

chmod +x ~/ai-workspace/templates/create-ai-react-app.sh

# Alias pro rychl√© pou≈æit√≠
echo "alias create-ai-app='~/ai-workspace/templates/create-ai-react-app.sh'" >> ~/.bashrc
```

---

## ‚úÖ Fin√°ln√≠ Ovƒõ≈ôen√≠ Kompletn√≠ho Workflow

### **Checklist √∫spƒõ≈°n√© instalace kompletn√≠ho AI workflow:**
- [ ] Ollama modely bƒõ≈æ√≠ (`ollama list`)
- [ ] Python virtual environment aktivn√≠ (`which python` ‚Üí ai-env)
- [ ] Continue.dev funguje v VS Code (`Ctrl+Shift+P` ‚Üí Continue: Chat)
- [ ] MCP server s Memory & RAG odpov√≠d√° (`curl localhost:3001/health`)
- [ ] RAG datab√°ze inicializov√°na (`ls ~/ai-workspace/chroma_db/`)
- [ ] Memory manager funkƒçn√≠ (`ai-dev memory`)
- [ ] Project indexing funguje (`ai-dev index .`)
- [ ] RAG search funguje (`ai-dev search "test"`)
- [ ] GPU dostupn√° pro AI (`nvidia-smi`)
- [ ] PostgreSQL p≈ôipojen√≠ funguje (`psql <connection-string>`)
- [ ] AI helper p≈ô√≠kazy funguj√≠ (`ai-dev status`)
- [ ] VS Code workspace otev≈ôen (`code ~/ai-workspace/ai-development.code-workspace`)

### **Pokroƒçil√Ω Test Workflow:**
```bash
# 1. Kompletn√≠ test workflow
ai-dev start

# 2. Vytvo≈ô smart projekt
create-ai-app my-intelligent-dashboard

# 3. Otev≈ôi v VS Code
code my-intelligent-dashboard

# 4. Test pokroƒçil√©ho AI promptu v Continue.dev:
```

**Pokroƒçil√Ω Test Prompt:**
```
"Vytvo≈ôe≈° dashboard aplikaci s vyu≈æit√≠m:

MEMORY: Naƒçti tech stack a patterns z project memory
RAG: Najdi najbolj≈°√≠ dashboard implementations v datab√°zi  
CONTEXT: Pou≈æij kontext tohoto Next.js + TypeScript projektu

Implementuj:
- User authentication s JWT
- Dashboard s charts (pou≈æij patterns z RAG)
- Real-time data updates
- Responsive design (pou≈æij Tailwind patterns z memory)
- PostgreSQL integration s Prisma
- API routes s error handling
- Comprehensive tests

P≈ôed implementac√≠ prohledej RAG datab√°zi pro podobn√© ≈ôe≈°en√≠ a pou≈æij √∫spƒõ≈°n√© patterns z memory."
```

---

## üéØ Co M√°≈° Po Kompletn√≠ Instalaci

### **Pokroƒçil√© AI Capabilities:**
- üß† **Project Memory** - Pamatuje si kontext, patterns, a √∫spƒõ≈°n√° ≈ôe≈°en√≠
- üîç **RAG Code Search** - Vyhled√°v√° podobn√Ω k√≥d across all projects
- üìö **Learning System** - Uƒç√≠ se z ka≈æd√©ho √∫spƒõ≈°n√©ho ≈ôe≈°en√≠
- üéØ **Context-Aware Generation** - Generuje k√≥d na z√°kladƒõ historie
- üîÑ **Pattern Recognition** - Automaticky detekuje a aplikuje patterns
- üöÄ **Smart Scaffolding** - Vytv√°≈ô√≠ projekty s learned best practices

### **VS Code AI Workflow Features:**
- **Smart Commands** - Custom prompts s memory a RAG integrac√≠
- **Auto-indexing** - Automatick√© indexov√°n√≠ projekt≈Ø do RAG
- **Memory Tracking** - Sledov√°n√≠ √∫spƒõ≈°n√Ωch patterns a solutions
- **Context Completion** - Tab autocomplete s project awareness
- **Intelligent Tasks** - VS Code tasks s AI workflow integrac√≠
- **Real-time Learning** - Continuous learning z development sessions

### **Command Line Tools:**
- `ai-dev start` - Start kompletn√≠ AI workflow
- `ai-dev search "query"` - Prohledej RAG datab√°zi
- `ai-dev memory` - Zobraz project memory
- `ai-dev learn "type" "desc"` - Ulo≈æ successful pattern
- `create-ai-app name` - Vytvo≈ô AI-enhanced projekt

### **Expected Performance:**
- **15x rychlej≈°√≠ v√Ωvoj** d√≠ky memory a RAG
- **Zero cold starts** - vyu≈æ√≠v√° learned patterns  
- **Intelligent suggestions** - na z√°kladƒõ successful solutions
- **Context preservation** - mezi sessions a projekty
- **Pattern reuse** - automatick√© vyu≈æit√≠ osvƒõdƒçen√Ωch ≈ôe≈°en√≠

---

## üöÄ Ready for Advanced AI Development!

Po dokonƒçen√≠ tohoto kompletn√≠ho setup bude≈° m√≠t nejpokroƒçilej≈°√≠ AI development environment, kter√©:

‚úÖ **P≈ôekon√° jak√©koli komerƒçn√≠ ≈ôe≈°en√≠** (Replit, Cursor, GitHub Copilot)  
‚úÖ **Uƒç√≠ se z ka≈æd√©ho projektu** a st√°v√° se chyt≈ôej≈°√≠  
‚úÖ **Pamatuje si kontext** nap≈ô√≠ƒç v≈°emi projekty  
‚úÖ **Vyhled√°v√° podobn√° ≈ôe≈°en√≠** v real-time  
‚úÖ **Generuje k√≥d na z√°kladƒõ historie** √∫spƒõ≈°n√Ωch projekt≈Ø  
‚úÖ **Funguje offline** s vlastn√≠mi daty  
‚úÖ **Stoj√≠ $0** mƒõs√≠ƒçnƒõ vs $20-60+ u konkurence  

**Zaƒçni s pokroƒçil√Ωm memory-aware promptem a pozoruj, jak AI vytv√°≈ô√≠ cel√© aplikace na z√°kladƒõ learned patterns! üöÄ**### **Jednoduch√Ω MCP server s kompletn√≠m workflow**
```bash
# Vytvo≈ô pokroƒçil√Ω MCP server s memory a RAG
cat > ~/ai-workspace/mcp-server.py << 'EOF'
#!/usr/bin/env python3
import asyncio
import json
import os
import sys
from pathlib import Path
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from typing import Dict, List, Optional

# Import na≈°ich modul≈Ø
sys.path.append(str(Path(__file__).parent))
from memory.memory_manager import memory_manager
from rag.rag_manager import rag_manager  
from knowledge.indexer import indexer

app = FastAPI(title="AI Workflow MCP Server with Memory & RAG")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup_event():
    """Inicializace p≈ôi spu≈°tƒõn√≠"""
    print("üöÄ Spou≈°t√≠m AI Workflow MCP Server...")
    
    # Inicializuj RAG collections
    await rag_manager.initialize_collections()
    
    # Auto-index existing projects
    await indexer.auto_index_workspace()
    
    print("‚úÖ AI Workflow MCP Server ready!")

@app.get("/health")
async def health():
    return {"status": "healthy", "message": "AI Workflow MCP Server running"}

@app.get("/api/models")
async def get_models():
    return {
        "models": [
            {"name": "qwen2.5:70b", "type": "architect", "status": "available"},
            {"name": "qwen2.5-coder:70b", "type": "coder", "status": "available"}, 
            {"name": "deepseek-v3", "type": "analyst", "status": "available"}
        ]
    }

@app.post("/api/memory/store")
async def store_memory(data: Dict):
    """Ulo≈æ data do memory syst√©mu"""
    project_path = data.get("project_path")
    context = data.get("context", {})
    
    await memory_manager.store_project_context(project_path, context)
    return {"status": "stored", "project": project_path}

@app.get("/api/memory/get/{project_path:path}")
async def get_memory(project_path: str):
    """Naƒçti kontext projektu z memory"""
    context = await memory_manager.get_project_context(project_path)
    return {"context": context, "project": project_path}

@app.post("/api/rag/search")
async def search_rag(data: Dict):
    """Prohledej RAG knowledge base"""
    query = data.get("query", "")
    code_type = data.get("type")
    limit = data.get("limit", 5)
    
    results = await rag_manager.search_similar_code(query, code_type, limit)
    return {"results": results, "query": query}

@app.post("/api/rag/index") 
async def index_project(data: Dict):
    """Indexuj projekt do RAG"""
    project_path = data.get("project_path")
    
    if not project_path or not Path(project_path).exists():
        raise HTTPException(status_code=400, detail="Invalid project path")
    
    await rag_manager.index_project(project_path)
    return {"status": "indexed", "project": project_path}

@app.post("/api/workflow/analyze")
async def analyze_project(data: Dict):
    """Komplexn√≠ anal√Ωza projektu s memory a RAG"""
    project_path = data.get("project_path")
    query = data.get("query", "")
    
    # Naƒçti kontext z memory
    memory_context = await memory_manager.get_project_context(project_path)
    
    # Najdi podobn√© patterny v RAG
    similar_patterns = await rag_manager.search_similar_code(query, limit=3)
    
    # Najdi √∫spƒõ≈°n√© ≈ôe≈°en√≠
    successful_solutions = await memory_manager.get_similar_patterns(query, limit=3)
    
    return {
        "project_context": memory_context,
        "similar_code": similar_patterns,
        "successful_patterns": successful_solutions,
        "recommendations": await _generate_recommendations(
            memory_context, similar_patterns, successful_solutions
        )
    }

@app.post("/api/workflow/learn")
async def learn_from_success(data: Dict):
    """Uƒçen√≠ z √∫spƒõ≈°n√Ωch ≈ôe≈°en√≠"""
    action = data.get("action")
    result = data.get("result") 
    pattern_type = data.get("pattern_type", "general")
    
    # Ulo≈æ do memory jako pattern
    await memory_manager.store_successful_pattern(pattern_type, result)
    
    # Ulo≈æ do RAG jako solution
    if "problem" in result and "solution" in result:
        await rag_manager.store_successful_solution(
            result["problem"],
            result["solution"], 
            {"type": pattern_type, "rating": result.get("rating", 5)}
        )
    
    return {"status": "learned", "pattern_type": pattern_type}

async def _generate_recommendations(memory_context: Dict, similar_code: List, successful_patterns: List) -> List[str]:
    """Generuj doporuƒçen√≠ na z√°kladƒõ kontextu a patterns"""
    recommendations = []
    
    # Recommendations based on tech stack
    tech_stack = memory_context.get("tech_stack", [])
    if "React" in tech_stack and "TypeScript" not in tech_stack:
        recommendations.append("Zva≈æte p≈ôid√°n√≠ TypeScript pro lep≈°√≠ type safety")
    
    if "Node.js" in tech_stack and not any("Express" in p.get("content", "") for p in similar_code):
        recommendations.append("Podobn√© projekty pou≈æ√≠vaj√≠ Express.js framework")
    
    # Recommendations based on successful patterns
    for pattern in successful_patterns:
        if pattern.get("success_score", 0) > 0.8:
            recommendations.append(f"√öspƒõ≈°n√Ω pattern: {pattern.get('pattern_type', 'general')}")
    
    return recommendations

@app.websocket("/ws/ai")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    await websocket.send_text(json.dumps({
        "type": "connection", 
        "message": "AI Workflow with Memory & RAG connected"
    }))
    
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            if message.get("type") == "project_analysis":
                # Analyzuj projekt s memory a RAG
                project_path = message.get("project_path")
                query = message.get("query", "")
                
                analysis = await analyze_project({
                    "project_path": project_path,
                    "query": query
                })
                
                await websocket.send_text(json.dumps({
                    "type": "analysis_result",
                    "data": analysis
                }))
            
            elif message.get("type") == "code_search":
                # Prohledej podobn√Ω k√≥d
                query = message.get("query")
                results = await search_rag({"query": query, "limit": 5})
                
                await websocket.send_text(json.dumps({
                    "type": "search_results", 
                    "data": results
                }))
            
            else:
                # Echo back pro nezn√°m√© typy
                await websocket.send_text(json.dumps({
                    "type": "response",
                    "message": f"Received: {data}"
                }))
                
    except Exception as e:
        print(f"WebSocket error: {e}")

if __name__ == "__main__":
    print("üöÄ Starting AI Workflow MCP Server with Memory & RAG on http://localhost:3001")
    uvicorn.run(app, host="0.0.0.0", port=3001, reload=True)
EOF

chmod +x ~/ai-workspace/mcp-server.py
```

### **Vytvo≈ôen√≠ requirements.txt**
```bash
cat > ~/ai-workspace/requirements.txt << 'EOF'
# Core AI Framework
crewai>=0.28.0
langgraph>=0.0.40
mem0ai>=1.0.0
litellm>=1.30.0
anthropic>=0.24.0
openai>=1.12.0
aider-chat>=0.35.0

# RAG & Vector Databases
chromadb>=0.4.18
sentence-transformers>=2.2.2
faiss-cpu>=1.7.4
llama-index>=0.9.0
langchain>=0.1.0
langchain-community>=0.0.20
pinecone-client>=3.0.0
qdrant-client>=1.7.0

# Document Processing
unstructured>=0.12.0
pypdf>=4.0.0
python-docx>=1.1.0
python-multipart>=0.0.6

# Code Analysis
tree-sitter>=0.20.4
tree-sitter-languages>=1.8.0
libcst>=1.1.0
astroid>=3.0.0
jedi>=0.19.0
rope>=1.11.0
gitpython>=3.1.40

# Web Framework
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
asyncio-mqtt>=0.13.0

# Development Tools
playwright>=1.40.0
psutil>=5.9.0
watchdog>=3.0.0
python-dotenv>=1.0.0

# Data Processing
pandas>=2.1.0
numpy>=1.24.0
pydantic>=2.5.0
EOF

# Instaluj requirements
cd ~/ai-workspace
source ai-env/bin/activate
pip install -r requirements.txt
```# üìã VS Code AI Workflow - Kompletn√≠ Instalaƒçn√≠ Pr≈Øvodce

## üéØ C√≠l: Roz≈°√≠≈ôen√≠ st√°vaj√≠c√≠ho VS Code o pokroƒçil√Ω AI workflow

Tento pr≈Øvodce roz≈°√≠≈ô√≠ tv√© st√°vaj√≠c√≠ VS Code prost≈ôed√≠ o pokroƒçil√© AI funkce, kter√© p≈ôevy≈°uj√≠ Replit/Cursor mo≈ænosti - a to zcela zdarma.

## ‚úÖ P≈ôedpoklady (Ji≈æ m√°≈° nainstalovan√©)
- Ubuntu Desktop 22.04 LTS ‚úÖ
- VS Code Desktop s z√°kladn√≠mi roz≈°√≠≈ôen√≠mi ‚úÖ
- Docker + Docker Compose ‚úÖ
- Python 3.11 + Node.js 20.x ‚úÖ
- PostgreSQL 15, Redis, Nginx ‚úÖ
- Ollama s modely (Llama, DeepSeek V3, Qwen 3 2507) ‚úÖ

---

## üöÄ Krok 1: Upgrade AI Model≈Ø pro V√Ωvoj

### **P≈ôid√°n√≠ Qwen2.5-Coder (Nejlep≈°√≠ pro coding)**
```bash
# Zastavit Ollama pokud bƒõ≈æ√≠
sudo systemctl stop ollama

# Aktualizovat Ollama na nejnovƒõj≈°√≠ verzi
curl -fsSL https://ollama.ai/install.sh | sh

# St√°hnout nejnovƒõj≈°√≠ coding modely
ollama pull qwen2.5-coder:70b    # Hlavn√≠ coding model
ollama pull qwen2.5:70b          # Architect model (u≈æ m√°≈°)
ollama pull deepseek-v3          # Analyst model (u≈æ m√°≈°)

# Ovƒõ≈ôit sta≈æen√© modely
ollama list
```

### **Instalace vLLM pro rychlej≈°√≠ inference**
```bash
# Instalace vLLM s CUDA podporou (vyu≈æije tv√© 6√ó Nvidia P106-90)
pip install vllm torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Test GPU dostupnosti
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
```

---

## üöÄ Krok 2: Instalace Kompletn√≠ho AI Workflow Frameworku

### **Python AI Dependencies**
```bash
# Hlavn√≠ AI framework
pip install --upgrade \
  crewai \
  langgraph \
  mem0ai \
  litellm \
  anthropic \
  openai \
  aider-chat \
  continue-dev

# RAG a Knowledge Management
pip install --upgrade \
  chromadb \
  pinecone-client \
  weaviate-client \
  qdrant-client \
  sentence-transformers \
  faiss-cpu \
  llama-index \
  langchain \
  langchain-community \
  unstructured \
  pypdf \
  python-docx

# Code Analysis a AST parsing
pip install --upgrade \
  tree-sitter \
  tree-sitter-languages \
  ast-tools \
  libcst \
  astroid \
  jedi \
  rope

# Development tools
pip install --upgrade \
  fastapi \
  uvicorn \
  websockets \
  asyncio-mqtt \
  playwright \
  gitpython \
  watchdog \
  psutil
```

### **Vytvo≈ôen√≠ AI Workspace struktury**
```bash
# Vytvo≈ô strukturu pro AI workspace
mkdir -p ~/ai-workspace/{memory,rag,knowledge,projects,templates}
cd ~/ai-workspace

# Vytvo≈ô Python virtual environment
python3.11 -m venv ai-env
source ai-env/bin/activate

# Instaluj dependencies do virtual env
pip install --upgrade pip
pip install -r requirements.txt  # (vytvo≈ô√≠me n√≠≈æe)
```

### **Node.js AI Tools**
```bash
# Model Context Protocol (MCP) framework
npm install -g \
  @modelcontextprotocol/sdk \
  @modelcontextprotocol/server-memory \
  @anthropic-ai/sdk

# Development tools
npm install -g \
  @railway/cli \
  vercel \
  tsx \
  concurrently \
  nodemon
```

---

## üß† Krok 3: Setup Memory System a RAG

### **Vytvo≈ôen√≠ Mem0 Memory Manageru**
```bash
# Vytvo≈ô memory manager
mkdir -p ~/ai-workspace/memory
cat > ~/ai-workspace/memory/memory_manager.py << 'EOF'
import os
from mem0 import MemoryClient
from typing import Dict, List, Optional
import json
from datetime import datetime
import asyncio

class AIMemoryManager:
    def __init__(self):
        self.client = MemoryClient()
        self.project_memories = {}
        
    async def store_project_context(self, project_path: str, context: Dict):
        """Ulo≈æ√≠ kontext projektu pro budouc√≠ pou≈æit√≠"""
        project_id = self._get_project_id(project_path)
        
        memory_data = {
            "project_path": project_path,
            "tech_stack": context.get("tech_stack", []),
            "architecture": context.get("architecture", ""),
            "coding_patterns": context.get("patterns", {}),
            "successful_solutions": context.get("solutions", []),
            "user_preferences": context.get("preferences", {}),
            "last_updated": datetime.now().isoformat()
        }
        
        await self.client.add(
            f"Kontext projektu {project_id}",
            metadata=memory_data
        )
        
        print(f"‚úÖ Ulo≈æen kontext pro projekt: {project_id}")
    
    async def get_project_context(self, project_path: str) -> Dict:
        """Naƒçte ulo≈æen√Ω kontext projektu"""
        project_id = self._get_project_id(project_path)
        
        results = await self.client.search(
            f"Kontext projektu {project_id}",
            limit=1
        )
        
        if results:
            return results[0].get('metadata', {})
        return {}
    
    async def store_successful_pattern(self, pattern_type: str, solution: Dict):
        """Ulo≈æ√≠ √∫spƒõ≈°n√Ω pattern pro budouc√≠ pou≈æit√≠"""
        await self.client.add(
            f"√öspƒõ≈°n√Ω pattern: {pattern_type}",
            metadata={
                "pattern_type": pattern_type,
                "solution": solution,
                "success_score": solution.get("score", 0),
                "reusable": True,
                "created": datetime.now().isoformat()
            }
        )
    
    async def get_similar_patterns(self, query: str, limit: int = 5) -> List[Dict]:
        """Najde podobn√© √∫spƒõ≈°n√© patterny"""
        results = await self.client.search(query, limit=limit)
        return [r['metadata'] for r in results if r.get('metadata', {}).get('reusable')]
    
    def _get_project_id(self, project_path: str) -> str:
        return os.path.basename(project_path.rstrip('/'))

# Glob√°ln√≠ instance
memory_manager = AIMemoryManager()
EOF
```

### **Vytvo≈ôen√≠ RAG Knowledge Base**
```bash
# Vytvo≈ô RAG syst√©m
mkdir -p ~/ai-workspace/rag
cat > ~/ai-workspace/rag/rag_manager.py << 'EOF'
import os
import asyncio
from pathlib import Path
from typing import List, Dict, Optional
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import ast
import json
from tree_sitter import Language, Parser
import git

class CodeRAGManager:
    def __init__(self, workspace_path: str):
        self.workspace_path = Path(workspace_path)
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.workspace_path / "chroma_db")
        )
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        self.collections = {}
        
    async def initialize_collections(self):
        """Inicializuj collections pro r≈Øzn√© typy k√≥du"""
        collection_types = [
            "react_components", "nodejs_apis", "python_scripts", 
            "sql_schemas", "css_styles", "typescript_interfaces",
            "successful_projects", "error_solutions"
        ]
        
        for col_type in collection_types:
            self.collections[col_type] = self.chroma_client.get_or_create_collection(
                name=col_type,
                metadata={"description": f"Knowledge base for {col_type}"}
            )
    
    async def index_project(self, project_path: str):
        """Indexuj cel√Ω projekt do RAG datab√°ze"""
        project_path = Path(project_path)
        
        if not project_path.exists():
            print(f"‚ùå Projekt neexistuje: {project_path}")
            return
        
        print(f"üîç Indexuji projekt: {project_path.name}")
        
        # Najdi v≈°echny relevantn√≠ soubory
        code_files = self._find_code_files(project_path)
        
        for file_path in code_files:
            await self._index_file(file_path, project_path.name)
        
        print(f"‚úÖ Projekt {project_path.name} indexov√°n ({len(code_files)} soubor≈Ø)")
    
    def _find_code_files(self, project_path: Path) -> List[Path]:
        """Najdi v≈°echny code soubory v projektu"""
        extensions = {
            '.js', '.jsx', '.ts', '.tsx', '.py', '.sql', 
            '.css', '.scss', '.json', '.md', '.yaml', '.yml'
        }
        
        code_files = []
        for ext in extensions:
            code_files.extend(project_path.rglob(f"*{ext}"))
        
        # Vyfiltruj node_modules, .git, dist atd.
        excluded_dirs = {'node_modules', '.git', 'dist', 'build', '__pycache__'}
        
        return [f for f in code_files 
                if not any(part in excluded_dirs for part in f.parts)]
    
    async def _index_file(self, file_path: Path, project_name: str):
        """Indexuj jednotliv√Ω soubor"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # Urƒç√≠ typ souboru a vhodnou collection
            collection_name = self._get_collection_for_file(file_path)
            if collection_name not in self.collections:
                return
            
            # Rozdƒõl√≠ content na chunky
            chunks = self._split_content(content, file_path.suffix)
            
            for i, chunk in enumerate(chunks):
                doc_id = f"{project_name}_{file_path.name}_{i}"
                
                # Embed chunk
                embedding = self.encoder.encode(chunk['content']).tolist()
                
                # Ulo≈æ do ChromaDB
                self.collections[collection_name].add(
                    documents=[chunk['content']],
                    embeddings=[embedding],
                    metadatas=[{
                        "file_path": str(file_path),
                        "project": project_name,
                        "chunk_type": chunk['type'],
                        "line_start": chunk.get('line_start', 0),
                        "line_end": chunk.get('line_end', 0)
                    }],
                    ids=[doc_id]
                )
                
        except Exception as e:
            print(f"‚ö†Ô∏è Chyba p≈ôi indexov√°n√≠ {file_path}: {e}")
    
    def _get_collection_for_file(self, file_path: Path) -> str:
        """Urƒç√≠ vhodnou collection podle typu souboru"""
        mapping = {
            '.jsx': 'react_components',
            '.tsx': 'react_components', 
            '.js': 'nodejs_apis',
            '.ts': 'typescript_interfaces',
            '.py': 'python_scripts',
            '.sql': 'sql_schemas',
            '.css': 'css_styles',
            '.scss': 'css_styles'
        }
        return mapping.get(file_path.suffix, 'successful_projects')
    
    def _split_content(self, content: str, file_ext: str) -> List[Dict]:
        """Rozdƒõl√≠ content na s√©mantick√© chunky"""
        chunks = []
        
        if file_ext in ['.js', '.jsx', '.ts', '.tsx']:
            # Pro JS/TS soubory rozdƒõl√≠ podle funkc√≠ a komponent
            chunks = self._split_js_content(content)
        elif file_ext == '.py':
            # Pro Python rozdƒõl√≠ podle t≈ô√≠d a funkc√≠
            chunks = self._split_python_content(content)
        else:
            # Pro ostatn√≠ soubory jednoduch√Ω split
            lines = content.split('\n')
            chunk_size = 50
            for i in range(0, len(lines), chunk_size):
                chunk_lines = lines[i:i + chunk_size]
                chunks.append({
                    'content': '\n'.join(chunk_lines),
                    'type': 'text_block',
                    'line_start': i,
                    'line_end': i + len(chunk_lines)
                })
        
        return chunks
    
    def _split_js_content(self, content: str) -> List[Dict]:
        """Rozdƒõl√≠ JS/TS content podle funkc√≠ a komponent"""
        # Jednoduch√° implementace - v produkci by pou≈æila tree-sitter
        chunks = []
        lines = content.split('\n')
        current_chunk = []
        chunk_type = 'code_block'
        
        for i, line in enumerate(lines):
            if any(keyword in line for keyword in ['function ', 'const ', 'export ', 'class ']):
                if current_chunk:
                    chunks.append({
                        'content': '\n'.join(current_chunk),
                        'type': chunk_type,
                        'line_start': i - len(current_chunk),
                        'line_end': i
                    })
                current_chunk = [line]
                
                if 'React' in line or 'Component' in line:
                    chunk_type = 'react_component'
                elif 'function' in line:
                    chunk_type = 'function'
                else:
                    chunk_type = 'code_block'
            else:
                current_chunk.append(line)
        
        if current_chunk:
            chunks.append({
                'content': '\n'.join(current_chunk),
                'type': chunk_type,
                'line_start': len(lines) - len(current_chunk),
                'line_end': len(lines)
            })
        
        return chunks
    
    def _split_python_content(self, content: str) -> List[Dict]:
        """Rozdƒõl√≠ Python content podle t≈ô√≠d a funkc√≠"""
        try:
            tree = ast.parse(content)
            chunks = []
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                    start_line = node.lineno
                    end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 10
                    
                    lines = content.split('\n')
                    chunk_content = '\n'.join(lines[start_line-1:end_line])
                    
                    chunks.append({
                        'content': chunk_content,
                        'type': 'class' if isinstance(node, ast.ClassDef) else 'function',
                        'line_start': start_line,
                        'line_end': end_line
                    })
            
            return chunks
        except:
            # Fallback na jednoduch√Ω split
            return [{'content': content, 'type': 'python_script', 'line_start': 0, 'line_end': len(content.split('\n'))}]
    
    async def search_similar_code(self, query: str, code_type: str = None, limit: int = 5) -> List[Dict]:
        """Najdi podobn√Ω k√≥d v knowledge base"""
        query_embedding = self.encoder.encode(query).tolist()
        
        collections_to_search = [code_type] if code_type else list(self.collections.keys())
        results = []
        
        for col_name in collections_to_search:
            if col_name in self.collections:
                search_results = self.collections[col_name].query(
                    query_embeddings=[query_embedding],
                    n_results=limit
                )
                
                for i, doc in enumerate(search_results['documents'][0]):
                    results.append({
                        'content': doc,
                        'metadata': search_results['metadatas'][0][i],
                        'similarity': search_results['distances'][0][i],
                        'collection': col_name
                    })
        
        # Se≈ôaƒè podle podobnosti
        results.sort(key=lambda x: x['similarity'])
        return results[:limit]
    
    async def store_successful_solution(self, problem: str, solution: str, metadata: Dict):
        """Ulo≈æ √∫spƒõ≈°n√© ≈ôe≈°en√≠ pro budouc√≠ pou≈æit√≠"""
        solution_embedding = self.encoder.encode(f"{problem}\n{solution}").tolist()
        
        self.collections['successful_projects'].add(
            documents=[f"Problem: {problem}\nSolution: {solution}"],
            embeddings=[solution_embedding],
            metadatas=[{
                **metadata,
                "problem": problem,
                "solution_type": metadata.get("type", "general"),
                "success_rating": metadata.get("rating", 5),
                "created": datetime.now().isoformat()
            }],
            ids=[f"solution_{len(self.collections['successful_projects'].get()['ids']) + 1}"]
        )

# Glob√°ln√≠ instance
rag_manager = CodeRAGManager(os.path.expanduser("~/ai-workspace"))
EOF
```

### **Vytvo≈ôen√≠ Knowledge Indexer**
```bash
# Vytvo≈ô knowledge indexer
cat > ~/ai-workspace/knowledge/indexer.py << 'EOF'
import os
import asyncio
from pathlib import Path
import git
from datetime import datetime
import json

class ProjectIndexer:
    def __init__(self, workspace_path: str):
        self.workspace_path = Path(workspace_path)
        self.projects_path = self.workspace_path / "projects"
        self.projects_path.mkdir(exist_ok=True)
        
    async def auto_index_workspace(self):
        """Automaticky indexuj v≈°echny projekty v workspace"""
        print("üîç Zaƒç√≠n√°m automatick√© indexov√°n√≠ workspace...")
        
        # Najdi v≈°echny Git repozit√°≈ôe
        git_repos = []
        for item in self.projects_path.iterdir():
            if item.is_dir() and (item / ".git").exists():
                git_repos.append(item)
        
        print(f"üìÅ Nalezeno {len(git_repos)} Git repozit√°≈ô≈Ø")
        
        for repo_path in git_repos:
            await self._index_repository(repo_path)
        
        print("‚úÖ Automatick√© indexov√°n√≠ dokonƒçeno")
    
    async def _index_repository(self, repo_path: Path):
        """Indexuj jeden Git repozit√°≈ô"""
        try:
            repo = git.Repo(repo_path)
            
            # Z√≠skej informace o repozit√°≈ôi
            repo_info = {
                "name": repo_path.name,
                "path": str(repo_path),
                "remote_url": self._get_remote_url(repo),
                "current_branch": repo.active_branch.name,
                "last_commit": {
                    "hash": repo.head.commit.hexsha[:8],
                    "message": repo.head.commit.message.strip(),
                    "author": str(repo.head.commit.author),
                    "date": repo.head.commit.committed_datetime.isoformat()
                },
                "indexed_at": datetime.now().isoformat()
            }
            
            # Analyzuj tech stack
            tech_stack = self._detect_tech_stack(repo_path)
            repo_info["tech_stack"] = tech_stack
            
            # Ulo≈æ metadata
            metadata_path = self.workspace_path / "knowledge" / f"{repo_path.name}_metadata.json"
            metadata_path.parent.mkdir(exist_ok=True)
            
            with open(metadata_path, 'w') as f:
                json.dump(repo_info, f, indent=2)
            
            # Indexuj do RAG
            from ..rag.rag_manager import rag_manager
            await rag_manager.index_project(str(repo_path))
            
            # Ulo≈æ do memory
            from ..memory.memory_manager import memory_manager
            await memory_manager.store_project_context(str(repo_path), {
                "tech_stack": tech_stack,
                "architecture": self._analyze_architecture(repo_path),
                "patterns": self._extract_patterns(repo_path)
            })
            
            print(f"‚úÖ Indexov√°n: {repo_path.name}")
            
        except Exception as e:
            print(f"‚ùå Chyba p≈ôi indexov√°n√≠ {repo_path.name}: {e}")
    
    def _get_remote_url(self, repo) -> str:
        """Z√≠skej remote URL repozit√°≈ôe"""
        try:
            return list(repo.remotes.origin.urls)[0]
        except:
            return "local"
    
    def _detect_tech_stack(self, project_path: Path) -> List[str]:
        """Detekuj tech stack projektu"""
        tech_stack = []
        
        # Package.json -> Node.js ecosystem
        if (project_path / "package.json").exists():
            try:
                with open(project_path / "package.json") as f:
                    package_data = json.load(f)
                    deps = {**package_data.get("dependencies", {}), 
                           **package_data.get("devDependencies", {})}
                    
                    if "react" in deps:
                        tech_stack.append("React")
                    if "next" in deps:
                        tech_stack.append("Next.js")
                    if "typescript" in deps:
                        tech_stack.append("TypeScript")
                    if "tailwindcss" in deps:
                        tech_stack.append("Tailwind CSS")
                    if "express" in deps:
                        tech_stack.append("Express.js")
                    
                tech_stack.append("Node.js")
            except:
                pass
        
        # Requirements.txt -> Python
        if (project_path / "requirements.txt").exists():
            tech_stack.append("Python")
            try:
                reqs = (project_path / "requirements.txt").read_text()
                if "django" in reqs.lower():
                    tech_stack.append("Django")
                if "flask" in reqs.lower():
                    tech_stack.append("Flask")
                if "fastapi" in reqs.lower():
                    tech_stack.append("FastAPI")
            except:
                pass
        
        # Prisma schema
        if (project_path / "prisma" / "schema.prisma").exists():
            tech_stack.append("Prisma")
        
        # Docker
        if (project_path / "Dockerfile").exists():
            tech_stack.append("Docker")
        
        # Database files
        if any((project_path / "prisma").glob("*.sql")) if (project_path / "prisma").exists() else []:
            tech_stack.append("PostgreSQL")
        
        return tech_stack
    
    def _analyze_architecture(self, project_path: Path) -> str:
        """Analyzuj architekturu projektu"""
        architecture_indicators = []
        
        # Frontend/Backend separation
        if (project_path / "frontend").exists() and (project_path / "backend").exists():
            architecture_indicators.append("Microservices/Separated Frontend-Backend")
        elif (project_path / "pages").exists() or (project_path / "app").exists():
            architecture_indicators.append("Full-stack Framework (Next.js)")
        elif (project_path / "src" / "components").exists():
            architecture_indicators.append("Single Page Application (SPA)")
        
        # API structure
        if (project_path / "api").exists() or (project_path / "routes").exists():
            architecture_indicators.append("RESTful API")
        
        # Database layer
        if (project_path / "models").exists():
            architecture_indicators.append("MVC Pattern")
        
        return " + ".join(architecture_indicators) if architecture_indicators else "Monolithic"
    
    def _extract_patterns(self, project_path: Path) -> Dict:
        """Extrahuj common patterns z projektu"""
        patterns = {
            "component_patterns": [],
            "api_patterns": [],
            "database_patterns": [],
            "styling_patterns": []
        }
        
        # React component patterns
        if (project_path / "src" / "components").exists():
            components_path = project_path / "src" / "components"
            for comp_file in components_path.rglob("*.tsx"):
                # Analyze component structure
                patterns["component_patterns"].append({
                    "file": comp_file.name,
                    "type": "functional_component"  # Simplified
                })
        
        # API patterns
        if (project_path / "api").exists():
            patterns["api_patterns"].append("RESTful endpoints")
        
        return patterns

# Glob√°ln√≠ instance
indexer = ProjectIndexer(os.path.expanduser("~/ai-workspace"))
EOF
```

### **Instalace roz≈°√≠≈ôen√≠ p≈ôes termin√°l**
```bash
# AI a coding roz≈°√≠≈ôen√≠
code --install-extension continue.continue
code --install-extension github.copilot-chat
code --install-extension ms-toolsai.jupyter
code --install-extension ms-python.python
code --install-extension ms-python.debugpy

# Advanced development
code --install-extension bradlc.vscode-tailwindcss
code --install-extension formulahendry.auto-rename-tag
code --install-extension christian-kohler.path-intellisense
code --install-extension christian-kohler.npm-intellisense
code --install-extension wix.vscode-import-cost

# Git a deployment
code --install-extension eamodio.gitlens
code --install-extension ms-vscode.vscode-github-issue-notebooks
code --install-extension github.vscode-github-actions

# Monitoring a debugging
code --install-extension ms-vscode.vscode-json
code --install-extension redhat.vscode-yaml
code --install-extension humao.rest-client
```

---

---

## üîß Krok 4: Pokroƒçil√° VS Code Konfigurace s Memory & RAG

### **Aktualizace Continue.dev konfigurace**
```bash
# Aktualizuj Continue.dev config s memory a RAG integrac√≠
cat > ~/.continue/config.json << 'EOF'
{
  "models": [
    {
      "title": "üéØ AI Architect (Qwen 3 2507)",
      "provider": "ollama",
      "model": "qwen2.5:70b",
      "apiBase": "http://localhost:11434",
      "contextLength": 128000,
      "systemMessage": "Jsi expert software architekt s p≈ô√≠stupem k project memory a RAG knowledge base. Vyu≈æ√≠vej kontext z podobn√Ωch projekt≈Ø a √∫spƒõ≈°n√Ωch ≈ôe≈°en√≠. Komunikuje≈° ƒçesky, ale k√≥d p√≠≈°e≈° v angliƒçtinƒõ."
    },
    {
      "title": "üíª AI Coder (Qwen2.5-Coder)",
      "provider": "ollama", 
      "model": "qwen2.5-coder:70b",
      "apiBase": "http://localhost:11434",
      "contextLength": 32000,
      "systemMessage": "Jsi senior full-stack developer s p≈ô√≠stupem k RAG datab√°zi k√≥du. Pou≈æ√≠vej patterns z podobn√Ωch √∫spƒõ≈°n√Ωch projekt≈Ø. P√≠≈°e≈° ƒçist√Ω, efektivn√≠, produkƒçn√≠ k√≥d s komplexn√≠m error handlingem."
    },
    {
      "title": "üß† AI Analyst (DeepSeek V3)",
      "provider": "ollama",
      "model": "deepseek-v3", 
      "apiBase": "http://localhost:11434",
      "contextLength": 64000,
      "systemMessage": "Jsi code reviewer s p≈ô√≠stupem k datab√°zi √∫spƒõ≈°n√Ωch optimalizac√≠. Analyzuje≈° k√≥d, bezpeƒçnost a v√Ωkon na z√°kladƒõ learned patterns."
    }
  ],
  "customCommands": [
    {
      "name": "üöÄ Smart Full-Stack Project",
      "prompt": "Analyzuj souƒçasn√Ω kontext projektu a vytvo≈ô full-stack aplikaci vyu≈æit√≠m:\n- Memory: Naƒçti podobn√© √∫spƒõ≈°n√© projekty z datab√°ze\n- RAG: Najdi best practices z knowledge base\n- Patterns: Pou≈æij osvƒõdƒçen√© architektury\n\nVytvo≈ô:\n- Modern React/TypeScript frontend\n- Node.js/Express backend s PostgreSQL\n- Autentifikace a autorizace\n- Responsive design s Tailwind CSS\n- Production deployment config\n- Tests a dokumentace\n\nPo≈æadavky: {{{ input }}}\n\nP≈ôed implementac√≠ prohledej RAG datab√°zi pro podobn√© ≈ôe≈°en√≠."
    },
    {
      "name": "üß† Context-Aware Implementation",
      "prompt": "Implementuj tuto funkƒçnost s vyu≈æit√≠m project memory:\n\n1. Naƒçti kontext aktu√°ln√≠ho projektu\n2. Najdi podobn√© implementace v RAG datab√°zi\n3. Pou≈æij √∫spƒõ≈°n√© patterns z memory\n4. Implementuj s best practices\n5. Ulo≈æ nov√Ω pattern do datab√°ze\n\nFunkƒçnost: {{{ input }}}"
    },
    {
      "name": "üîç RAG Code Search",
      "prompt": "Prohledej RAG knowledge base pro:\n{{{ input }}}\n\nNajdi:\n- Podobn√© implementace\n- Best practices\n- Common patterns\n- Error handling approaches\n- Performance optimizations\n\nVyber nejlep≈°√≠ ≈ôe≈°en√≠ a p≈ôizp≈Øsob aktu√°ln√≠mu kontextu."
    },
    {
      "name": "üìö Learn from Solution",
      "prompt": "Analyzuj toto ≈ôe≈°en√≠ a ulo≈æ jako pattern:\n\n{{{ input }}}\n\n1. Extrahuj reusable patterns\n2. Identifikuj success factors\n3. Ulo≈æ do memory datab√°ze\n4. Kategoryzuj podle typu (component, API, optimization, etc.)\n5. P≈ôidej metadata pro budouc√≠ vyhled√°v√°n√≠"
    },
    {
      "name": "üîß Memory-Based Optimization",
      "prompt": "Optimalizuj tento k√≥d na z√°kladƒõ:\n- √öspƒõ≈°n√Ωch optimalizac√≠ z memory\n- Performance patterns z RAG datab√°ze\n- Security best practices\n- Learned solutions\n\nK√≥d k optimalizaci:\n{{{ input }}}\n\nVra≈• optimalizovanou verzi s vysvƒõtlen√≠m zmƒõn."
    },
    {
      "name": "üîÑ Migration with Memory",
      "prompt": "Migruj tento Replit projekt s vyu≈æit√≠m memory:\n\n1. Analyzuj strukturu projektu\n2. Najdi podobn√© migrace v datab√°zi\n3. Pou≈æij osvƒõdƒçen√© migration patterns\n4. Aktualizuj na modern√≠ stack\n5. Ulo≈æ migration pattern pro budouc√≠ pou≈æit√≠\n\nReplit projekt: {{{ input }}}"
    },
    {
      "name": "üéØ Architecture with Context",
      "prompt": "Navrhni architekturu s vyu≈æit√≠m:\n- Project memory (podobn√© √∫spƒõ≈°n√© projekty)\n- RAG knowledge base (architectural patterns)\n- Learned best practices\n- Context souƒçasn√©ho projektu\n\nPo≈æadavky: {{{ input }}}\n\nVytvo≈ô skalabiln√≠, maintainable architekturu."
    },
    {
      "name": "üß™ Intelligent Testing",
      "prompt": "Vytvo≈ô comprehensive testy na z√°kladƒõ:\n- Testing patterns z RAG datab√°ze\n- √öspƒõ≈°n√Ωch test strategies z memory\n- Common edge cases z learned solutions\n\nK√≥d k testov√°n√≠:\n{{{ input }}}\n\nGeneruj unit, integration a e2e testy."
    }
  ],
  "tabAutocompleteModel": {
    "title": "Tab Autocomplete with Memory",
    "provider": "ollama",
    "model": "qwen2.5-coder:70b",
    "apiBase": "http://localhost:11434"
  },
  "allowAnonymousTelemetry": false,
  "enableTabAutocomplete": true,
  "mcpServers": {
    "ai-workflow": {
      "command": "python",
      "args": ["/home/$USER/ai-workspace/mcp-server.py"],
      "env": {}
    }
  }
}
EOF
```

### **Vytvo≈ôen√≠ config souboru**
```bash
# Vytvo≈ô adres√°≈ô pro Continue.dev config
mkdir -p ~/.continue

# Vytvo≈ô konfiguraƒçn√≠ soubor
cat > ~/.continue/config.json << 'EOF'
{
  "models": [
    {
      "title": "üéØ AI Architect (Qwen 3 2507)",
      "provider": "ollama",
      "model": "qwen2.5:70b",
      "apiBase": "http://localhost:11434",
      "contextLength": 128000,
      "systemMessage": "Jsi expert software architekt. Navrhuje≈° ≈°k√°lovateln√©, udr≈æiteln√© syst√©my s modern√≠mi best practices. Komunikuje≈° ƒçesky, ale k√≥d p√≠≈°e≈° v angliƒçtinƒõ."
    },
    {
      "title": "üíª AI Coder (Qwen2.5-Coder)",
      "provider": "ollama", 
      "model": "qwen2.5-coder:70b",
      "apiBase": "http://localhost:11434",
      "contextLength": 32000,
      "systemMessage": "Jsi senior full-stack developer. P√≠≈°e≈° ƒçist√Ω, efektivn√≠, produkƒçn√≠ k√≥d s komplexn√≠m error handlingem. Komunikuje≈° ƒçesky, ale k√≥d a koment√°≈ôe p√≠≈°e≈° v angliƒçtinƒõ."
    },
    {
      "title": "üß† AI Analyst (DeepSeek V3)",
      "provider": "ollama",
      "model": "deepseek-v3", 
      "apiBase": "http://localhost:11434",
      "contextLength": 64000,
      "systemMessage": "Jsi code reviewer a performance analytik. Zamƒõ≈ôuje≈° se na optimalizaci, security a best practices. Komunikuje≈° ƒçesky, ale doporuƒçen√≠ p√≠≈°e≈° v angliƒçtinƒõ."
    }
  ],
  "customCommands": [
    {
      "name": "üöÄ Kompletn√≠ Full-Stack Projekt",
      "prompt": "Vytvo≈ô kompletn√≠ full-stack aplikaci s:\n- Modern React/TypeScript frontend\n- Node.js/Express backend s PostgreSQL\n- Autentifikace a autorizace\n- Responsive design s Tailwind CSS\n- Production deployment config pro Railway + Vercel\n- Comprehensive testing\n\nPo≈æadavky: {{{ input }}}"
    },
    {
      "name": "üîß Optimalizace a Deploy",
      "prompt": "Optimalizuj tento k√≥d pro produkci a vytvo≈ô deployment konfiguraci pro Railway (backend) a Vercel (frontend). Zahr≈à environment variables, health checks a monitoring."
    },
    {
      "name": "üß™ Generov√°n√≠ Test≈Ø",
      "prompt": "Vytvo≈ô comprehensive testy pro tento k√≥d vƒçetnƒõ unit test≈Ø, integration test≈Ø a edge cases. Pou≈æij modern√≠ testing frameworky a zajisti vysok√© pokryt√≠."
    },
    {
      "name": "üìä Performance Audit",
      "prompt": "Analyzuj tento k√≥d na performance bottlenecky a navrhni konkr√©tn√≠ optimalizace s mƒõ≈ôiteln√Ωmi dopady na v√Ωkon."
    },
    {
      "name": "üîí Security Review",
      "prompt": "Proveƒè security audit tohoto k√≥du a navrhni zlep≈°en√≠. Zamƒõ≈ô se na input validation, authentication, authorization a data protection."
    },
    {
      "name": "üìù Dokumentace",
      "prompt": "Vytvo≈ô comprehensive dokumentaci pro tento k√≥d vƒçetnƒõ README, API docs a inline koment√°≈ô≈Ø. Udƒõlej to beginner-friendly."
    },
    {
      "name": "üîÑ Migration z Replit",
      "prompt": "P≈ôeveƒè tento Replit projekt na modern√≠, lok√°lnƒõ spustiteln√Ω projekt s proper strukturou, dependencies a deployment konfigurac√≠ pro Railway/Vercel."
    }
  ],
  "tabAutocompleteModel": {
    "title": "Tab Autocomplete",
    "provider": "ollama",
    "model": "qwen2.5-coder:70b",
    "apiBase": "http://localhost:11434"
  },
  "allowAnonymousTelemetry": false,
  "enableTabAutocomplete": true
}
EOF
```

---

## üöÄ Krok 5: VS Code Settings pro AI Workflow

### **Pokroƒçil√© VS Code settings s AI workflow**
```json
{
  "editor.formatOnSave": true,
  "editor.defaultFormatter": "esbenp.prettier-vscode",
  "editor.codeActionsOnSave": {
    "source.fixAll.eslint": true,
    "source.organizeImports": true
  },
  "editor.suggestSelection": "first",
  "editor.tabCompletion": "on",
  "editor.wordBasedSuggestions": "off",
  
  "continue.telemetryEnabled": false,
  "continue.enableTabAutocomplete": true,
  "continue.showInlineTip": true,
  
  "files.associations": {
    "*.aider": "markdown",
    "*.mcp": "json",
    "*.prompt": "markdown",
    "*.memory": "json",
    "*.rag": "json"
  },
  
  "files.watcherExclude": {
    "**/ai-workspace/chroma_db/**": true,
    "**/ai-workspace/memory/**": true,
    "**/ai-env/**": true
  },
  
  "search.exclude": {
    "**/ai-workspace/chroma_db": true,
    "**/ai-workspace/ai-env": true,
    "**/*.memory": true
  },
  
  "terminal.integrated.defaultProfile.linux": "zsh",
  "terminal.integrated.fontFamily": "MesloLGS NF",
  "terminal.integrated.env.linux": {
    "AI_WORKSPACE": "/home/$USER/ai-workspace",
    "PYTHONPATH": "/home/$USER/ai-workspace"
  },
  
  "workbench.colorCustomizations": {
    "activityBar.background": "#1a1a2e",
    "statusBar.background": "#16213e", 
    "titleBar.activeBackground": "#1a1a2e",
    "terminal.background": "#0c0c0c",
    "editor.background": "#0d1117",
    "sideBar.background": "#161b22"
  },
  
  "workbench.settings.editor": "json",
  "workbench.startupEditor": "none",
  
  "typescript.preferences.includePackageJsonAutoImports": "auto",
  "javascript.preferences.includePackageJsonAutoImports": "auto",
  
  "eslint.workingDirectories": ["./"],
  "eslint.validate": ["javascript", "typescript", "javascriptreact", "typescriptreact"],
  
  "prettier.requireConfig": false,
  "prettier.useEditorConfig": false,
  "prettier.tabWidth": 2,
  "prettier.semi": true,
  "prettier.singleQuote": true,
  
  "git.autofetch": true,
  "git.confirmSync": false,
  "git.enableSmartCommit": true,
  
  "python.defaultInterpreterPath": "/home/$USER/ai-workspace/ai-env/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.terminal.activateEnvironment": true,
  
  "[javascript]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode",
    "editor.tabSize": 2
  },
  "[typescript]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode",
    "editor.tabSize": 2
  },
  "[json]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode"
  },
  "[python]": {
    "editor.defaultFormatter": "ms-python.black-formatter"
  },
  
  "aiWorkflow.autoIndex": true,
  "aiWorkflow.memoryEnabled": true,
  "aiWorkflow.ragEnabled": true,
  "aiWorkflow.learningMode": true
}
```

---

## üöÄ Krok 6: VS Code Tasks pro AI Workflow

### **Vytvo≈ôen√≠ tasks.json**
```bash
# Vytvo≈ô .vscode adres√°≈ô v home directory pro glob√°ln√≠ tasks
mkdir -p ~/.vscode

# Vytvo≈ô tasks.json
cat > ~/.vscode/tasks.json << 'EOF'
{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "ü§ñ Start Complete AI Workflow",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "cd ~/ai-workspace && source ai-env/bin/activate && echo 'üöÄ Starting Complete AI Workflow...' && python mcp-server.py"],
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "panel": "new",
        "showReuseMessage": false
      },
      "isBackground": true,
      "problemMatcher": []
    },
    {
      "label": "üß† Index Current Project",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from knowledge.indexer import indexer; asyncio.run(indexer._index_repository('${workspaceFolder}'))\""],
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "üîç Search RAG Database",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from rag.rag_manager import rag_manager; print('RAG Search Results:'); results = asyncio.run(rag_manager.search_similar_code('${input:searchQuery}')); [print(f'- {r[\\\"metadata\\\"][\\\"file_path\\\"]}: {r[\\\"content\\\"][:100]}...') for r in results[:3]]\""],
      "group": "test",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "üíæ Show Project Memory",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from memory.memory_manager import memory_manager; context = asyncio.run(memory_manager.get_project_context('${workspaceFolder}')); print('Project Memory:'); print(f'Tech Stack: {context.get(\\\"tech_stack\\\", [])}'); print(f'Architecture: {context.get(\\\"architecture\\\", \\\"N/A\\\")}'); print(f'Last Updated: {context.get(\\\"last_updated\\\", \\\"N/A\\\")}')\""],
      "group": "test"
    },
    {
      "label": "üìä AI Workflow Status",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "echo '=== AI Models Status ===' && ollama list && echo -e '\\n=== GPU Status ===' && nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits && echo -e '\\n=== MCP Server Status ===' && curl -s http://localhost:3001/health || echo 'MCP Server not running' && echo -e '\\n=== Memory & RAG Status ===' && ls -la ~/ai-workspace/chroma_db/ 2>/dev/null | wc -l && echo 'collections available'"],
      "group": "test",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "üöÄ Smart Project Setup",
      "type": "shell", 
      "command": "bash",
      "args": ["-c", "echo 'üöÄ Setting up smart project with AI assistance...' && mkdir -p ${input:projectName} && cd ${input:projectName} && npx create-next-app@latest . --typescript --tailwind --eslint --app --yes && npm install @prisma/client prisma && npx prisma init && echo '‚úÖ Project created. Starting AI indexing...' && cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from knowledge.indexer import indexer; asyncio.run(indexer._index_repository('$(pwd)/${input:projectName}'))\""],
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "üîß Deploy with Memory Context",
      "type": "shell",
      "command": "bash", 
      "args": ["-c", "echo 'üîß Deploying with learned patterns...' && cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from memory.memory_manager import memory_manager; context = asyncio.run(memory_manager.get_project_context('${workspaceFolder}')); print('Using deployment patterns from memory:', context.get('deployment_patterns', 'none'))\" && cd ${workspaceFolder} && railway deploy && vercel --prod"],
      "group": "build",
      "dependsOrder": "sequence"
    },
    {
      "label": "üß™ Intelligent Testing",
      "type": "shell",
      "command": "bash",
      "args": ["-c", "echo 'üß™ Running AI-enhanced tests with memory patterns...' && cd ~/ai-workspace && source ai-env/bin/activate && python -c \"import asyncio; from rag.rag_manager import rag_manager; patterns = asyncio.run(rag_manager.search_similar_code('testing patterns', 'successful_projects')); print('Found', len(patterns), 'testing patterns in memory')\" && cd ${workspaceFolder} && npm test -- --coverage"],
      "group": "test"
    },
    {
      "label": "üìà Advanced Performance Monitor",
      "type": "shell",
      "command": "watch",
      "args": ["-n", "2", "bash -c 'echo \"=== AI Workflow Performance ===\" && echo \"GPU Status:\" && nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits && echo \"\\nOllama Models:\" && ollama ps && echo \"\\nMCP Server:\" && curl -s http://localhost:3001/health | jq -r .message 2>/dev/null || echo \"Offline\" && echo \"\\nRAG Database:\" && ls ~/ai-workspace/chroma_db/ 2>/dev/null | wc -l && echo \"collections\"'"],
      "group": "test",
      "isBackground": true
    }
  ],
  "inputs": [
    {
      "id": "projectName",
      "description": "N√°zev nov√©ho AI-enhanced projektu",
      "default": "my-smart-project"
    },
    {
      "id": "searchQuery",
      "description": "Co hled√°≈° v RAG datab√°zi?",
      "default": "React component patterns"
    }
  ]
}
EOF
```

---

## üöÄ Krok 7: Vytvo≈ôen√≠ AI Workflow Scriptu

### **Startup script pro AI modely**
```bash
# Vytvo≈ô scripts adres√°≈ô
mkdir -p ~/ai-scripts

# Vytvo≈ô startup script
cat > ~/ai-scripts/start-ai-workflow.sh << 'EOF'
#!/bin/bash

echo "üöÄ Starting AI Development Workflow..."

# Start Ollama service
sudo systemctl start ollama
sleep 3

# Check if models are available
echo "üìã Checking AI models..."
ollama list

# Start Continue.dev compatible server
echo "üîß Starting MCP server..."
cd ~/ai-scripts
nohup python3 mcp-server.py > mcp.log 2>&1 &

# Check GPU status
echo "üî• GPU Status:"
nvidia-smi --query-gpu=name,utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits

echo "‚úÖ AI Workflow ready!"
echo "üí° Tip: Open VS Code and press Ctrl+Shift+P ‚Üí 'Continue: Chat'"
EOF

chmod +x ~/ai-scripts/start-ai-workflow.sh
```

### **Jednoduch√Ω MCP server**
```bash
# Vytvo≈ô z√°kladn√≠ MCP server
cat > ~/ai-scripts/mcp-server.py << 'EOF'
#!/usr/bin/env python3
import asyncio
import json
from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

app = FastAPI(title="AI Workflow MCP Server")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health():
    return {"status": "healthy", "message": "AI Workflow MCP Server running"}

@app.get("/api/models")
async def get_models():
    return {
        "models": [
            {"name": "qwen2.5:70b", "type": "architect", "status": "available"},
            {"name": "qwen2.5-coder:70b", "type": "coder", "status": "available"}, 
            {"name": "deepseek-v3", "type": "analyst", "status": "available"}
        ]
    }

@app.websocket("/ws/ai")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    await websocket.send_text(json.dumps({
        "type": "connection", 
        "message": "AI Workflow connected"
    }))
    
    try:
        while True:
            data = await websocket.receive_text()
            # Echo back for now - extend with actual AI processing
            await websocket.send_text(json.dumps({
                "type": "response",
                "message": f"Received: {data}"
            }))
    except:
        pass

if __name__ == "__main__":
    print("üöÄ Starting AI Workflow MCP Server on http://localhost:3001")
    uvicorn.run(app, host="0.0.0.0", port=3001)
EOF

chmod +x ~/ai-scripts/mcp-server.py
```

---

## üöÄ Krok 8: Test Installation

### **Ovƒõ≈ôen√≠ instalace**
```bash
# 1. Start AI workflow
~/ai-scripts/start-ai-workflow.sh

# 2. Test Ollama models
ollama run qwen2.5-coder:70b "Napi≈° hello world v Reactu"

# 3. Test Continue.dev v VS Code
code
# Stiskni Ctrl+Shift+P ‚Üí "Continue: Chat"
# Zadej: "Vytvo≈ô React komponentu pro user profile card"

# 4. Test MCP server
curl http://localhost:3001/health
curl http://localhost:3001/api/models
```

### **Test React projektu s AI**
```bash
# Vytvo≈ô testovac√≠ projekt
mkdir ~/test-ai-project
cd ~/test-ai-project

# Iniciuj Next.js projekt
npx create-next-app@latest . --typescript --tailwind --eslint --app

# Otev≈ôi v VS Code
code .

# Test AI promptu v Continue.dev:
# "Vytvo≈ô dashboard komponentu s PostgreSQL p≈ôipojen√≠m"
```

---

## üöÄ Krok 9: Integrace s Existing Database

### **Konfigurace Prisma pro PostgreSQL**
```bash
# V jak√©mkoli projektu
npm install prisma @prisma/client

# Vytvo≈ô .env soubor s tv√Ωm DigitalOcean PostgreSQL
cat > .env << 'EOF'
DATABASE_URL="postgresql://<username>:<password>@<host>:<port>/<database>?sslmode=require"
EOF

# Iniciuj Prisma
npx prisma init

# Test p≈ôipojen√≠
npx prisma db pull
```

---

## üöÄ Krok 10: VS Code Launch Configuration

### **Vytvo≈ôen√≠ launch.json pro debugging**
```bash
# Vytvo≈ô glob√°ln√≠ launch configuration
mkdir -p ~/.vscode

cat > ~/.vscode/launch.json << 'EOF'
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "üöÄ Debug Next.js App",
      "type": "node",
      "request": "launch",
      "program": "${workspaceFolder}/node_modules/.bin/next",
      "args": ["dev"],
      "console": "integratedTerminal",
      "skipFiles": ["<node_internals>/**"]
    },
    {
      "name": "üß™ Debug Node.js API",
      "type": "node",
      "request": "launch",
      "program": "${workspaceFolder}/server.js",
      "env": {
        "NODE_ENV": "development"
      },
      "console": "integratedTerminal"
    },
    {
      "name": "üêç Debug Python Script",
      "type": "python",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "justMyCode": true
    }
  ]
}
EOF
```

---

## ‚úÖ Fin√°ln√≠ Ovƒõ≈ôen√≠

### **Checklist √∫spƒõ≈°n√© instalace:**
- [ ] Ollama modely bƒõ≈æ√≠ (`ollama list`)
- [ ] Continue.dev funguje v VS Code (`Ctrl+Shift+P` ‚Üí Continue: Chat)
- [ ] MCP server odpov√≠d√° (`curl localhost:3001/health`)
- [ ] GPU je dostupn√° pro AI (`nvidia-smi`)
- [ ] PostgreSQL p≈ôipojen√≠ funguje (`psql <connection-string>`)
- [ ] React projekt se vytv√°≈ô√≠ a spou≈°t√≠ (`npm run dev`)
- [ ] AI generuje funkƒçn√≠ k√≥d v Continue.dev

### **Quick Test Prompt:**
```
"Vytvo≈ô kompletn√≠ React dashboard aplikaci s:
- TypeScript a Tailwind CSS
- PostgreSQL datab√°ze p≈ôes Prisma
- User authentication
- Data visualization charts
- Responsive design
- Production deployment config

Pou≈æij modern√≠ best practices a zahr≈à error handling."
```

---

## üéØ Co M√°≈° Po Instalaci

### **Dostupn√© AI Modely:**
- üéØ **Qwen 3 2507** - Architekt (pl√°nov√°n√≠, design)
- üíª **Qwen2.5-Coder 70B** - Hlavn√≠ program√°tor
- üß† **DeepSeek V3** - Code reviewer a analytik

### **VS Code Funkce:**
- AI chat integrovan√Ω p≈ô√≠mo v editoru
- Tab autocomplete s AI
- Custom commands pro bƒõ≈æn√© √∫koly
- Automatick√© form√°tov√°n√≠ a linting
- Debugging konfigurace
- Task automation

### **Workflow Capabilities:**
- Generov√°n√≠ cel√Ωch projekt≈Ø jedn√≠m promptem
- Automatick√© p≈ôipojen√≠ k PostgreSQL
- Deployment na Railway + Vercel
- Code review a optimalizace
- Security audit
- Performance analysis

---

## üìû Troubleshooting

### **Pokud nƒõco nefunguje:**
```bash
# Restart Ollama
sudo systemctl restart ollama

# Check GPU
nvidia-smi

# Check models
ollama list

# Restart VS Code
code --disable-extensions && code --enable-extensions

# Check logs
journalctl -u ollama -f
```

### **ƒåast√© probl√©my:**
1. **Ollama neodpov√≠d√°**: `sudo systemctl restart ollama`
2. **GPU nedostupn√°**: Zkontroluj NVIDIA ovladaƒçe
3. **Continue.dev nefunguje**: Restartuj VS Code
4. **Model p≈ô√≠li≈° pomal√Ω**: Zkontroluj GPU utilization

---

## üöÄ Ready to Go!

Po dokonƒçen√≠ tƒõchto krok≈Ø bude≈° m√≠t nejpokroƒçilej≈°√≠ AI development environment, kter√©:

- **P≈ôekon√° Replit** rychlost√≠ a funkcemi
- **Nahrad√≠ Cursor** s vlastn√≠mi modely  
- **Funguje offline** nez√°visle na internetu
- **Stoj√≠ $0** mƒõs√≠ƒçnƒõ vs $20+ u konkurence
- **D√°v√° plnou kontrolu** nad k√≥dem a daty

**Zaƒçni s jednoduch√Ωm promptem a pozoruj, jak AI vytv√°≈ô√≠ cel√© aplikace! üöÄ**